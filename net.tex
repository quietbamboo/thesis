\chapter{MobiPerf: characterizing 3G/4G network performance} \label{chap:net}

Given the wide adoption of smartphone platforms, such as iOS and Android, there is a growing number of popular mobile applications designed for these platforms. For many of these applications, including web browser, email, VoIP, social networks, network access is required. Even for games that are often run locally, ranking systems and online peer matching systems are widely adopted which also requires network access, \eg Game Center for iOS. As a result, mobile data traffic volume is sky-rocketing. For example, AT\&T's mobile data volumes surged by a staggering 8,000\% from 2007 to 2010~\cite{att.overload}. Hence, it is critical to understand the {\em network performance} in cellular networks, and such understanding is a prerequisite to study smartphone application performance and optimizations. Smartphone customers want to know the cellular network performance in order to choose carriers and devices to use; mobile network operators care about cellular network performance to ensure the quality of service.

Systematically quantifying the cellular network performance is not straightforward. The challenges are multifold:
\begin{itemize}
\item It is not easy to reuse existing open-source network performance measurement tools due to smartphone operating system constraints. For example, iOS does not allow us to run a command-line program unless we jailbreak the device.
\item Conducting measurements from a single or a few vantage points is not sufficient for large cellular carriers. This is because the network condition and user load may vary across locations and without a reasonable number of sample users, the measurement results may not be representative. This forces us to abandon the idea to carry out all measurements ourselves, but instead to provide a tool for real smartphone users to use for network performance measurement.
\item As the measurement tool is intended to be run by real smartphone users, who do not necessarily have any computer science background, we have to design the tool in a way that is easy for these users to make network measurements.
\item The selection of the set of metrics for quantifying the cellular network performance is critical, as we want to collect sufficient information about the network performance within a period of user-tolerable time. Existing similar tools, such as Speedtest.net~\cite{speedtestnet} 
and FCC's broadband test~\cite{fccspeedtest}, only measure bandwidth and latency in cellular networks and ignore other important metrics such as DNS lookup time, \etc The measurement methodology also requires careful design, \eg bandwidth measurements in cellular networks need support from geo-distributed server nodes.
\end{itemize}


In the following of this chapter, we first discuss the design and implementation of \mobiperf, the tool to characterize cellular network performance in Section~\ref{sec:net.design}. Then we discuss the measurement results collected via \mobiperf and implications in Section~\ref{sec:net.result}.


\nsection{MobiPerf Design and Methodology}
\label{sec:net.design}

Inspired by previous work in the Internet, \eg~Netalyzr~\cite{netalyzr}, which collects measurement data from volunteers, we develop a measurement platform, \mobiperf, used by real users on their smartphones to build a comprehensive data set for cellular networks. The public deployment of \mobiperf overcomes the limitation of a single vantage point and short time duration for locally conducted measurements and provides a representative data set on cellular network performance in the real world.

\mobiperf covers a more comprehensive set of metrics than existing public network performance measurement tools available in iOS or Android, such as DNS lookup, Ping to the first hop, \etc. We next describe the metrics we use for evaluating network performance and how we compute them. To minimize the impact of the performance limiting factors in the Internet path, we leverage the M-Lab~\cite{mlab} support and make \mobiperf always choose the closest server node(s) for measurement. \mobiperf server suite is deployed to 46 M-Lab nodes across the world, covering North America, Europe, Asia, and Australia.  Each node has 4-core 2.00 GHz Intel Xeon CPU and our virtual slice has 4GB memory and 100Mbps Ethernet network access, which ensures that the network bottleneck is unlikely on the wired network path. Specifically, 23 nodes are within the U.S., spreading across major cities in different parts of the country. 

To characterize cellular network performance, we use TCP throughput, downlink RTT, retransmission rate, local DNS lookup time, TCP handshake time, and Ping latency to the first responsive IP hop as our metrics. TCP is of particular interest, since most network applications use TCP. An application session usually requires DNS lookup, and every TCP connection begins with a TCP handshake. Hence these two factors contribute heavily to user-perceived performance of many network applications. Ping latency to the first responsive hop provides an estimate of the latency of the wireless hop.

\paragraph{DNS lookup}
For the DNS experiment, \mobiperf sends DNS requests to resolve a list of selected popular domain names. We use Alexa~\cite{alexa} top sites to select the top URLs and the list we use was downloaded in 2009 (Appendix~\ref{app:dns}). By tuning the size of the list and going through the list sequentially twice, we ensure that during the second lookup the names are highly likely cached at the local DNS (LDNS) server in carrier networks but not on the phone based on observed latencies. This is achievable since compared to the phone the LDNS server typically has a larger DNS cache. 


\paragraph{RTT and variation test}
LTE has significantly smaller latency compared with 3G~\cite{tr25.913}, hence the network distance between users and the measurement servers for the wired Internet path becomes less negligible. Given that the GPS coordinates for M-Lab nodes are known, in \mobiperf, a nearest M-Lab node is selected for a user based on the current GPS location if available, or the IP address otherwise, with the help of a IP address to GPS coordinates mapping~\cite{maxmind}. Such a mapping is sufficient for our purpose of finding coarse-grained location estimates for server selection.

To measure RTT and variation, \mobiperf repeatedly establishes a new TCP connection with the server and measures the delay between {\sf SYN} and {\sf SYN-ACK} packet. Both the median of these RTT measurements and the variation are reported to our central server. For some cellular ISPs, traffic may be redirected to a middlebox, which replies a {\sf SYN-ACK} packet to the client on behalf of the server. In this case, the measured RTT is between the client and the middlebox. However, this RTT is the user-perceived delay for TCP connection establishment and we think it is fine to use it for comparison purpose.

To measure TCP handshake to server nodes in diverse physical locations, \mobiperf sends TCP {\em connect} requests to different M-Lab nodes distributed across the U.S. To characterize Ping latency, our tool Pings \url{www.google.com} with increasing TTL values starting from 1 and records the IP address and the corresponding RTT. \mobiperf also Pings different M-Lab nodes to obtain the delay distribution to diverse Internet locations. 

\paragraph{TCP throughput}
Since single-threaded TCP measurement is more sensitive to packet loss and hence less accurate~\cite{sigcomm.broadband}, we use multi-threaded TCP measurement in \mobiperf to estimate the {\em peak channel capacity}, \ie three nearest server nodes in M-Lab are selected for each user at runtime to start concurrent threads for throughput test. Despite the shared nature of M-Lab nodes with other test tools, it is unlikely that all three selected nodes are overloaded in terms of CPU and network.

A throughput test lasts for 20 seconds, to balance across bandwidth usage, user waiting time and measurement accuracy. The initial 5 seconds are ignored empirically due to TCP slow start. The remaining 15 seconds are separated into 15 1-second bins. The average throughput for each bin is calculated and the median of all bins is the measured throughput. Compared with using average throughput, median more accurately estimates the steady peak throughput by reducing the impact of abnormal bins, \eg a very high-value bin due to initial buffering or a low-value bin due to temporary signal problem. Uplink and downlink tests share the same methodology. Packet traces are collected at the server side to calculate TCP retransmission rate. 

\nsection{MobiPerf Deployment and User Statistics}

\mobiperf~\cite{mobiperf} project was initiated in 2008 and the name of the measurement tool was \TT~\cite{mobiperf, mobisys.3gtest} at the time. We made it publicly available on different smartphone platforms, which allows us to characterize cellular network performance in multiple cellular carriers at diverse locations over an extended duration. With significant UI and methodology improvements, we changed the name to be \FT~\cite{4gtest} in 2011. In 2012, we further decided to change the tool name to be \mobiperf and made it open source~\cite{mobiperf.repo}. Initially, \mobiperf was supported for iOS, Android and Windows Phone platforms and later, due to time limit and OS constraints, we decided to focus our efforts on the Android platform. At the time this dissertation is being written, \mobiperf is under active development with joint efforts from University of Michigan, University of Washington, and M-Lab~\cite{mlab}, and it is being used as basis for research projects and commercial products of multiple organizations.

\begin{figure}[t]
\centering
\IG{figures/srii/coverage_all2.eps}\\ %coverage_all.eps is the original eps figure, loading it is laggy
\ncaption{User coverage of \mobiperf}
\label{fig:net.coverage}
\end{figure}

\begin{table} [t]
\begin{center}
\begin{tabular}{|c|c|c|c|c|}\hline
 & Android & iOS & Win Mobile & All\\\hline
User & 39.3K 39.7\% & 47.0K 47.4\% & 12.8K 12.9\% & 99.1K \\\hline
Run & 273.8K 62.3\% & 127.0K 28.9\% & 38.7K 8.8\% & 439.5K \\\hline
\end{tabular}
\ncaption{\mobiperf User and run breakdown of different platforms}
\label{tab:net.user}
\end{center}
\end{table}

We publicly deployed the \mobiperf application in August, 2009, distributed via Apple's App Store, Google's Android Market and Microsoft's Windows Marketplace for Mobile. Ever since the initial deployment, we have been continuously improving and releasing updates for iOS and Android version of our app. Till April, 2011, 99.1K users from across the world have run our app for 439.5K times. The number of users and runs for three different platforms, including iOS, Android, and Windows Mobile, is listed in Table~\ref{tab:net.user}. The average number of runs for each Android user is larger than the other two platforms, because for the Android version of our app, we give an option to the users to periodically run the tests. We observe users from 179 countries or regions according to the collected GPS information. Since GPS information for Windows Mobile users is seldom available, for most top countries of the other two platforms, we do not observe any Windows Mobile users. GPS information may sometimes be unavailable as well on Android and iOS, due to signal problem or users not wishing to share their location information. Among all 93.3K users, 63.7K (68.27\%) have GPS readings and 52.24\% of them are from the U.S., and among these 63.7K users, about 1.0K (1.57\%) users have run our app in more than one countries or regions. We also observe more than 800 carrier names. However, carriers may adopt different names in different countries, making it difficult to accurately estimate the actual number of carriers. Figure~\ref{fig:net.coverage} shows the user coverage of \mobiperf, with one dot representing one run of \mobiperf. Given the wide coverage of regions, we believe our data set is fairly representative of the entire smartphone population, especially for North America with denser user distribution. In this study, our analysis mostly focuses on U.S. users.


\nsection{3G Network Characterization}
\label{sec:net.3g}
%purpose
We first focus on characterizing the performance of commercial 3G networks with the \mobiperf data set, complemented by local controlled experiments.

\begin{table} [!t]
\footnotesize
\begin{center}
\begin{tabular}{|l||c|c|c|c|c|}\hline
%\begin{tabular*}{1\textwidth}%
%     {@{\extracolsep{\fill}}|l||c|c|c|c|}\hline
Referred to as   & iPhone & Palm        & Samsung          & G2 & HTC \\\hline\hline
Carrier         & AT\&T     & Sprint         & Verizon    & T-Mobile & AT\&T \\\hline
Network         & UMTS      & EVDO           & EVDO       & UMTS     & UMTS \\\hline
Advertised Downlink(Mbps)$^\star$ & 0.7-1.7 & 0.6-1.4      & 0.6-1.4        & 0.6-1.0  & 0.7-1.7 \\\hline
Advertised Uplink(Mbps)$^\star$  & 0.5-1.2 & 0.35-0.5      & 0.5-0.8       & 0.3-0.7  & 0.5-1.2 \\\hline\hline
Vendor          & Apple     & Palm           & Samsung    & HTC      & HTC \\\hline
Device          & iPhone & Treo800w      & SCHi760        & Android G2       & TyTnII \\\hline
Memory (MB)     & 128     & 128          & 64             & 192      & 128 \\\hline
Processor (ARM) & 1176      & 1136  & 920T    & 1136EJS & 1136EJS \\\hline
CPU frequency (MHz) & 620       & 333            & 400    & 528      & 400 \\\hline
OS              & iPhone OS 2.1    & WM 6.1$^\dag$         & WM 6.1        & Android 1.6 & WM 6.1 \\\hline
Browser         & Safari & IE          & IE            & Browser App & IE  \\\hline
\end{tabular}
\ncaption{Device specifications and 3G network carriers$^\natural$}
\label{table:net.device}
\begin{tabular}{l}
\\{\small $^\star$All advertised data rate was for the time in 2009.}
\\{\small $^\dag$WM stands for Windows Mobile}
\\{\small $^\natural$At the time of this piece of study (2009), these devices represent state of the art of smartphones.}
\end{tabular}
\end{center}
\end{table}

Table~\ref{table:net.device} lists the devices used and carriers studied in the local controlled experiments. We studied four major carriers in the U.S., AT\&T, Sprint, Verizon, and T-Mobile. They split between UMTS/HSPA (AT\&T and T-Mobile) and EVDO (Sprint 
and Verizon). AT\&T has the highest advertised downlink and uplink data rates. The actual data rates that a user can attain depend on many factors, such as signal strength, location, and background traffic. One of our goals is to understand how the actual data rates match the advertised ones and which factors have the biggest impact on network performance.

\nsubsection{Comparison across Carriers}
\label{sec:net.carrier}
 % figures of general network statistics from 3GTest
 
\begin{figure*}[th!]
\centering
\begin{tabular}{cc}
\IGM{figures/mobisys10/all_all_thru_down_cdf_cmp.eps} &
\IGM{figures/mobisys10/all_all_rtt_down_cdf_cmp.eps} \\
\small{(a) CDF of downlink TCP throughput} &
\small{(b) CDF of downlink TCP round trip time} \\
\IGM{figures/mobisys10/all_all_thru_up_cdf_cmp.eps} &
\IGM{figures/mobisys10/all_all_lr_down_cdf_cmp.eps} \\
\small{(c) CDF of uplink TCP throughput} &
\small{(d) CDF of downlink TCP retransmission rate} \\
\IGM{figures/mobisys10/ping.eps} &
\IGM{figures/mobisys10/1sthop.eps} \\
\small{(e) CDF of Ping latency to landmark servers} &
\small{(f) CDF of Ping latency to the first hop} \\
\IGM{figures/mobisys10/dns.eps} & 
\IGM{figures/mobisys10/handshake.eps} \\
\small{(g) CDF of DNS lookup time} & 
\small{(h) TCP handshake time to landmark servers} \\
\end{tabular}
\ncaption{TCP performance comparison among carriers (data from deployed application \mobiperf, only considering U.S.)}
\label{fig:net.general}
\end{figure*}
 
Figures~\ref{fig:net.general}(a) illustrates measured TCP downlink
throughput. Given stable TCP throughput is roughly inversely
proportional to RTT and to the square root of packet loss 
rate~\cite{Padhye:TCPModel:sigcomm1998}, we also analyze RTT and 
retransmission rate. In Figure~\ref{fig:net.general}(b), all carriers 
show comparable RTT distributions, with T-Mobile showing slightly 
larger RTT values and correspondingly lower downlink TCP 
throughput. Various reasons contribute to large RTT in 3G networks, 
\eg~queueing delays at the base station or other internal nodes, such as RNC, SGSN, and GGSN in UMTS networks. Large RTTs may also be due to packet loss recovered through link layer retransmission, which we do not have direct information about.

Figure~\ref{fig:net.general}(c) plots measured TCP uplink throughput.
Unlike downlink throughput, AT\&T and T-Mobile have lower uplink
throughput compared with Sprint and Verizon. One of the reasons 
could be the lack of support for UMTS/HSUPA on the phones used for 
AT\&T and T-Mobile. Even the latest version of iPhone 3GS does not 
claim to support HSUPA. 
%Sprint and Verizon's 3G networks based on EVDO technologies do not have these problems. 
The median uplink throughput for AT\&T and T-Mobile ranges from 
200 kbps to 300 kbps, while that for Sprint and Verizon is around 
400 kbps. 

Figure~\ref{fig:net.general}(d) shows that Verizon and Sprint exhibit
slightly higher TCP retransmission rate, matching observations from 
our local experiments. %This likely results in lower downlink TCP throughput. 
On average, AT\&T's downlink throughput outperforms that of the 
other carriers due to its relatively lower RTT and loss rate. The 
median of TCP downlink throughput for all carriers ranges from 500 
kbps to 1 Mbps. Median RTT varies from 300 ms to 500 ms, suggesting 
400 ms is a representative delay value to emulate 3G networks. AT\&T 
and T-Mobile have a median retransmission rate of 0\%, while that 
for Sprint and Verizon is 0.7\%.

Figures~\ref{fig:net.general}(e)(f) show that Ping latency to the 
first responsive hop is close to that to landmark servers, suggesting
that the first responsive hop consisting of 3G wireless link 
contributes to most of the delay along the end-to-end network path. 
Note that Ping latency to the first responsive hop actually refers 
to the first IP hop responding to ICMP probing. For AT\&T and 
T-Mobile, the first IP hop, when TTL is set to 1, does not respond
in most cases.
Only the second IP hop replies with a private IP address. For 
Sprint and Verizon, the first IP hop does reply with a public IP 
address. The median latency to the first responsive hop ranges 
from 150 ms to 200 ms, while that to landmark servers is between 
180 ms and 250 ms. We observe that both the Ping latency and TCP 
handshake time are smaller than RTT values measured in TCP downlink 
experiments. 
%likely due to
%the queueing delay imposed on larger packets for downlink measurements
%at the internal nodes of 3G networks such as the base-station.


%We attempt to focus on DNS lookup performance of local DNS servers when results
%are cached at these servers to eliminate variability of external
%lookups.
%We exclude lookups that appear to be satisfied directly by
%the client locally with no network traffic or answered with very small
%delays. 
Figure~\ref{fig:net.general}(g) shows DNS lookup performance. We design 
the experiment in a way that all DNS lookups are cached at the LDNS 
server but not locally on the phone (\S\ref{sec:3GTest}). This allows 
us to more accurately estimate the delay to the LDNS servers. 
The LDNS servers studied tend not to respond to ICMP packets, making 
it challenging to directly measure the network delay between the 
phone and LDNS server. From the results, we found that all carriers 
exhibit similar trend with median values close to 200 ms. Given that 
the DNS lookup delay is already close to Ping latency to the first 
responsive hop, there is limited room for improving DNS lookup 
performance.

As shown in Figure~\ref{fig:net.general}(h), the median of TCP handshake 
delay ranges from 160 ms to 200 ms, close to the Ping latency to the 
first responsive hop in Figure~\ref{fig:net.general}(f). We also observe 
that the relative ranking among all carriers is consistent with that 
in Figure~\ref{fig:net.general}(f). Compared with Figure~\ref{fig:net.general}(b), 
large packets with size close to MTU (\eg 1348 bytes in AT\&T) are 
found to have 2 -- 4 times of the RTT for small packets.


\nsubsection{Performance Comparison among Mobile Network Technologies}

%\comment{cite 3GTest MobiSys paper and highlight difference: further breakdown into UMTS and CDMA, also contains data for a longer duration 19 months v.s. 9 months. Or maybe talk about this in Intro?}

\begin{figure*}[t]
\centering
\begin{tabular}{cc}
\IGM{figures/srii/down_tp.eps} &
\IGM{figures/srii/up_tp.eps} \\
\small{(a) Downlink throughput} &
\small{(b) Uplink throughput} \\
\IGM{figures/srii/down_rtt.eps} &
\IGM{figures/srii/down_tp_3g.eps} \\
\small{(c) Downlink RTT} &
\small{(d) Downlink throughput} \\
\IGM{figures/srii/up_tp_3g.eps} &
\IGM{figures/srii/down_rtt_3g.eps} \\
\small{(e) Uplink throughput} &
\small{(f) Downlink RTT} \\
\end{tabular}
\ncaption{Downlink/Uplink performance comparison among different types of networks}
\label{fig:net.nettype}
\end{figure*}

We compare the cellular network performance among technology types. We first break down technology types into WiFi, UMTS family, CDMA family, EDGE and GPRS. UMTS and CDMA are considered as 3G, while EDGE and GPRS are two types of older technologies. 
Within 3G family, we select 4 major network types, including HSDPA, UMTS (without HSDPA), 1xRTT and EVDO\_A, since these network types cover most 3G users. Notice that at the time of this part of study\comment{cite SRII tech report}, LTE has not come into market yet and we leave the study of LTE in Section~\ref{xxx}\comment{ref LTE network performance section}.

Downlink throughput is compared in Figure~\ref{fig:net.nettype}~(a).
WiFi has the best performance with median throughput of 1.46 Mbps. For
3G network, UMTS family appears to outperform CDMA family, with median
downlink throughput of 964 kbps compared to 368 kbps. EDGE lags
with median downlink throughput 112 kbps and GPRS is the slowest at 45
kbps. The ranking of downlink retransmission rate is consistent with
that of downlink throughput, except that UMTS and CDMA have similar
retransmission rate distribution. In
Figure~\ref{fig:net.nettype}~(c), UMTS's median RTT is 495 ms,
smaller than CDMA's 680 ms. This helps explain the throughput gap
between UMTS and CDMA, since TCP throughput is lower with higher RTT
and loss rate. Among 3G networks shown in
Figure~\ref{fig:net.nettype}~(d), HSDPA has the highest median
downlink throughput of 1.18 Mbps and 1xRTT has the smallest throughput of 115 kbps, since it is one of the earliest CDMA 3G technologies. Similarly, we observe high RTT in Figure~\ref{fig:net.nettype}~(f) and high retransmission rate for 1xRTT correlated with its low throughput.

We closely study the variation of TCP downlink RTT, often known as jitter. It is an important metric to evaluate network performance for streaming video, VoIP, and online gaming applications, \eg high variation causes intermittent video playing, voice calls and lags for online games. In Figure~\ref{fig:net.nettype}(f), each data point in this figure corresponds to the standard deviation of all RTT samples in one downlink TCP flow, \ie one user's downlink experiment. Compared with WiFi, whose median of RTT standard deviation is 41 ms, UMTS has a higher value of 93 ms and 233 ms for CDMA. If applications running on smartphones fail to tolerate this high variation in RTT, user experience would be degraded.

In Figure~\ref{fig:net.nettype}~(b) , the uplink throughput difference between UMTS and CDMA is less obvious compared with downlink. For example, at $50^{th}$ percentile, UMTS's uplink throughput is 110 kbps and CDMA's is 120 kbps. Within the 3G family, as shown in Figure~\ref{fig:net.nettype}~(e), all network types experience less than 150 kbps median uplink throughput.

These results can be taken into consideration by network application developers to have better support of various network conditions.



\nsubsection{Time of Day Correlation}
\label{sec:net.tod}

\begin{figure}[thb]
\centering
\IG{figures/mobisys10/tod.eps} \\
\ncaption{Number of \mobiperf users vs. time of day}
\label{fig:net.uservstod}
\end{figure} 

Understanding whether traffic patterns exhibit any time of day
behavior is useful for improving the design of applications and mobile
network infrastructure. %Despite some dedicated resources allocated to
%each user, there is still resource sharing among users, especially
%those within close physical proximity. 
We expect smartphone users to have diurnal patterns in their behavior. 
For example, we can observe such a pattern in Figure~\ref{fig:net.uservstod}.
To further understand its impact on performance, we resort to conducting local controlled experiments.

To measure the network performance over a long time period, we created an internal version of \mobiperf and installed it on the smartphones listed in Table~\ref{table:net.device}. \mobiperf is modified to record the signal strength on the Samsung and Palm phones, and continuously conducts measurements every 10 minutes to collect one week's data (excluding weekends) in Ann Arbor, MI. We make sure that the phones are placed at the same location with excellent signal strength during the entire measurement study. Since the data is collected continuously for a long period of time, it can be used for characterizing the time-of-day effect. The results for the 5 contiguous weekdays are shown in Figure~\ref{fig:net.tod}. 

\begin{figure*}[t]
\centering
\begin{tabular}{cc}
\IGM{figures/mobisys10/time_down.eps} &
\IGM{figures/mobisys10/time_rtt.eps} \\
\small{(a) TCP downlink throughput vs. time of day} & 
\small{(b) TCP round trip time vs. time of day} \\ 
\IGM{figures/mobisys10/time_loss.eps} &
\IGM{figures/mobisys10/time_up.eps} \\
\small{(c) TCP retransmission rate vs. time of day} &
\small{(d) TCP uplink throughput vs. time of day} \\
%\includegraphics[width=0.45\textwidth]{figures/net_signal/signal.eps} \\
%\small{(d) TCP downlink throughput / signal strength vs. time of day}\\ 
\end{tabular}
\ncaption{Correlation between TCP performance and time of day (local controlled experiments)}
\label{fig:net.tod}
\end{figure*}

First, time of day effect is less pronounced for uplink throughput 
compared to downlink throughput, comparing Figure~\ref{fig:net.tod}(a) and (d).
This is likely due to higher demand 
for downlink capacity by popular applications such as web browsing 
and video streaming. Second, we observe an obvious time pattern for 
AT\&T's downlink throughput. At night and early morning hours, between 
2AM and 8AM, the downlink throughput can reach 1 Mbps. However, the 
downlink throughput of lower than 500 kbps is observed at other times. 
This phenomenon is possibly due to the large number of iPhone users 
and the large traffic volume brought by various network applications.
For Sprint and Verizon, we observe similar though less prominent trend 
compared to that for AT\&T. For T-Mobile, the TCP downlink throughput 
is more stable, which we conjecture is due to the fact that its 3G 
service has only recently become available at our location.

Figures~\ref{fig:net.tod}(b)(c) indicate that RTT and 
retransmission rate exhibit time of day pattern for some carriers. 
For AT\&T, the downlink throughput is found to be mostly affected by 
RTT values, likely to be caused by queueing delays in AT\&T's 3G 
networks. RTT varies from 300 ms during late nights to as high as 
700 ms at peak times. For Verizon and Sprint, the RTT values are 
more stable, though with varying TCP retransmission rate. One 
possible explanation is that in Verizon and Sprint's 3G networks, 
shared queues would drop packets once the queue length exceeds a
threshold. This design will restrict the variation of RTT but incur 
more packet loss. %It is difficult to verify such hypothesis without visibility
%into the 3G network internals.


\begin{figure*}[t]
\centering
\begin{tabular}{cc}
\IGM{figures/srii/down_tp_carrier.eps} &
\IGM{figures/srii/down_rtt_carrier.eps} \\
\small{(a) Downlink throughput} &
\small{(b) Downlink RTT} \\
\multicolumn{2}{c}{\IGM{figures/srii/down_rttdev_carrier.eps}}   \\
\multicolumn{2}{c}{\small{(c) Downlink RTT standard deviation}}  \\
\end{tabular}
\ncaption{Time of day pattern of downlink performance for major carriers in the U.S. (\mobiperf data set, large packets)}
\label{fig:net.tod.carrier}
\end{figure*}

We further analyze the time-of-day pattern using the \mobiperf data set collected across locations. Figure~\ref{fig:net.tod.carrier} shows the
aggregate time of day analysis of TCP downlink throughput, RTT, and
jitter for all AT\&T, T-Mobile, and Verizon 3G users in the U.S. Each
data point is median value of all data samples across locations in the
U.S. within an hour based on user's local time. This analysis
technique avoid potential bias by a specific small group of users or any particular locations.

\begin{figure}[t]
\centering
\IG{figures/srii/rtt_local_att.eps}\\
\ncaption{Delay in AT\&T 3G network (small packets)}
\label{fig:net.tod.rtt.att}
\end{figure}

Figure~\ref{fig:net.tod.carrier}~(a) shows that AT\&T has the most clear time of day pattern for downlink throughput, confirming previous local controlled experiments. 
%, with a maximum difference of around 100\% (3:00 AM vs. 12:00PM).
Verizon has less obvious yet still observable diurnal pattern for
downlink throughput and even less obvious for T-Mobile. TCP
retransmission rate for these carriers stays low consistently at
different hours, hence the diurnal pattern of TCP downlink RTT in
Figure~\ref{fig:net.tod.carrier}~(b) explains the throughput fluctuation,
especially for AT\&T. The standard deviation for TCP downlink RTT also
demonstrates a clear diurnal pattern for AT\&T and Verizon, while less
obvious for T-Mobile shown in Figure~\ref{fig:net.tod.carrier}~(c).

These observations suggest that applications with intensive network download requirement and little tolerance on RTT jitter may experience worse performance during peak hours. Uplink and LDNS performance are relatively consistent across different hours of day, indicating that the infrastructure support is capable of handling peak hours for such operations. However, for downlink, network resource at peak hours becomes a bottleneck.

Given that the downlink RTT in Figure~\ref{fig:net.tod.carrier} (b) is for large packets, mostly with a size of MTU, we also study the diurnal pattern of small packets. For T-Mobile, similar to Figure~\ref{fig:net.tod.carrier}~(b), we do not observe any time of day effect on RTT. For AT\&T, in Figure~\ref{fig:net.tod.rtt.att} showing RTT of small packets (100 bytes) with boxplot, at the median level, there is no diurnal pattern for RTT. At the $75^{th}$ percentile, 12:00PM and 1:00PM have larger RTT values, and at the $95^{th}$ percentile, hours between 10:00 AM and 6:00 PM clearly have much larger RTTs. This indicates that during peak hours, most small packets do not experience longer delay, but some (at least 5\%) experience much longer RTTs. By comparing with large packets, our local experiment suggests that small packets have less obvious, yet still observable diurnal pattern for AT\&T.

 
\nsubsection{Signal Strength Effects}
\label{sec:net.signal}

Signal strength is an important factor that affects 3G network
performance, since higher signal-to-noise ratio (SNR) allows higher 
bit rate. We therefore also carried out experiments to understand
this correlation. Since it is not easy for us to control the signal
strength, we continuously monitor signal strength and TCP downlink
throughput for a week. We highlight 
our major observations here. When the signal strength is too weak, 
TCP connections will disconnect. When signal strength is at some 
middle range, we observe clear correlation between signal strength 
and TCP downlink throughput. TCP downlink throughput is not affected 
by the signal strength if the latter is above some threshold. Given 
these observations, we exclude the data points corresponding to poor 
signal strength from the \mobiperf data set and controlled experiment data set.

\nsubsection{Smartphone v.s. Laptop}
\label{sec:net.platform}

To understand whether the computation capability of a smartphone
limits its 3G network performance, we set up a controlled experiment to
compare a smartphone (iPhone 3G) with a laptop (ThinkPad T42). The 
laptop can access AT\&T's 3G network via a wireless data card, while 
the iPhone measurement is conducted at the same location and the 
same time. We found that the distribution of downlink throughput is 
similar, implying that the performance bottleneck is within the 
3G network instead of on the phone. However, for other 
compute-intensive applications, the performance difference is
more pronounced. We will study this in more details in \S\ref{sec:web.js}\comment{TBD}.

\noindent\textbf{Summary:} The main observations of 3G network
performance are the following.

\begin{enumerate}
\item Typical values for 3G throughput range from 500 kbps to 1~Mbps
for downlink, and 200 kbps to 400 kbps for uplink, both lower than 
the advertised rates.

\item Network performance differs across all carriers. For downlink 
RTT and throughput, the differences among carriers are evident.

\item Sprint and Verizon have higher TCP retransmission rate 
compared with AT\&T and T-Mobile.

\item Large packets can have 2--4 times RTT of small packets.

\item Some carriers show clear time of day patterns on weekdays, 
especially for AT\&T's downlink throughput.

\item For simple TCP downloading/uploading, the performance 
bottleneck is within the 3G network.

\item 3G wireless delay dominates the end-to-end RTT.
\end{enumerate}

\comment{TBU}
Our observations suggest that the low uplink throughput and large
RTT of current 3G networks raise challenges for offloading computation 
into the cloud. Network application designers should avoid chatty 
protocols and minimize total bytes to transfer. 3G operators need to 
examine their queueing and link layer retransmission policies to 
reduce latency in wireless links. 



+ Results
+ Implications (compare across network types, compare over time)

talk about results from public deployment, also talk about the results in local controlled experiments via mobiperf, such as mobility test. This is another part of results for cellular network performance.
