\chapter{Related Work}
\label{chap:related}

In this chapter, we summarize related work in different categories.

\nsection{Characterizing Mobile Network Usage and Performance}

Netdiff system~\cite{Mahajan:NSDI2008:NetDiff} establishes a benchmark for comparing performance of different ISPs. In our research, we attempt to establish an equivalent benchmark for comparing network application performance on smartphones. Although there are some existing tools available for such comparison, \eg \texttt{speedtest.net}~\cite{speedtestnet} and FCC's broadband test~\cite{fccspeedtest}, which measure the throughput and latency in 3G networks, \mobiperf covers a more comprehensive set of metrics, including DNS lookup, Ping to the first hop, TCP handshake, and HTTP request to landmark servers, \etc Existing studies have compared 3G and WiFi performance on smartphones~\cite{Gass:3GWiFi:PAM2010} and studied the influence of the packet size on the delay in 3G networks~\cite{Arlos:OneWay:PAM2010}. Jiang \etal examine how large buffers in cellular networks contribute to significant TCP queuing delay~\cite{jiang12}. Tan \etal carried out a similar measurement study on multiple commercial 3G networks~\cite{wltan07}. However, their study is limited to one location (Hong Kong) and a few devices. Compared with their study, our work covers significantly more users from many different locations. Netalyzr~\cite{netalyzr} carries out network measurement for Internet users, not for smartphone users.

Regarding cellular network infrastructure, Xu \etal characterized 3G data network infrastructures, leading to an observation that the routing of cellular data traffic is quite restricted as traffic must traverse through a small number of gateway nodes~\cite{sigmetrics.cluster}. Wang \etal unveiled cellular carriers' NAT and firewall policies~\cite{sigcomm.nat}. Balakrishnan \etal investigated IP address dynamics in 3G networks. They found that cellular IPs embed much less geographical information than wired IPs do~\cite{Mahesh:Ephemera:IMC09}. 
%In our previous work~\cite{sigmetrics.cluster}, we made qualitative observations on the effectiveness of CDN service in cellular networks and the geographical coverage of LDNS servers. In this study, with a comprehensive end-to-end latency measurement data set, we quantify the effectiveness of adopting different CDN servers for cellular networks. We also provide fine-grained analysis of the geographical coverage of each individual IP address of LDNS servers and discuss the implication on performance and reliability.

Existing work has built tools to infer traffic differentiation policies from either local experiments or public deployment~\cite{imc.netpolice, nsdi.glasnost, windrider}. And our work is among the first attempts to systematically uncover the previously unknown network policy in cellular networks.

Prior efforts~\cite{falaki10_mobisys, shepard10, qian13_pam} deploy smartphone user studies and collect data from tens to hundreds of participating users. Those studies investigate various aspects including the diversity of smartphone users, the popularity of mobile applications, and the effectiveness of compression techniques on cellular traffic \etc Our study features a much larger user base of around 300K customers using the LTE networks whose characteristics are far from being well understood. Some previous studies also perform large-scale measurement of mobile networks and smartphones. Sommers \etal compare cellular and Wi-Fi performance using crowd-sourced data from \texttt{speedtest.net} covering 15 metro areas, focusing on throughput and latency~\cite{sommers12}. Xu \etal profile diverse usage behaviors of smartphone applications~\cite{xu11_imc}. Qian \etal perform network-wide measurement studies of cellular periodic transfers~\cite{qian12_www}. In contrast, our investigated spectrum is more diverse, covering traffic characteristics, network performance, protocol interaction, bandwidth utilization, and application usage in the increasingly popular LTE networks. We also compare our results with those presented in~\cite{sommers12}. Some previous studies~\cite{gember11, chen12} also examined mobile handsets using Wi-Fi networks.


\nsection{Characterizing Smartphone Application Performance}

There have been several studies focusing on mobile users from the perspective of applications, such as a study no the bottlenecks of web browsers' performance~\cite{hotmobile.web}, a study~\cite{Ionut:Serendipity:IMC09} which characterizes the relationship between users' application interests and mobility, and another study~\cite{Mahesh:Ephemera:IMC09} which examines the possibility of geolocating IP address in 3G networks. Other related measurement works of cellular data networks include a study of traffic characteristics on mobile devices~\cite{Maier:Traffic:PAM2010}, and performance analysis of TCP/IP over 3G network with rate and delay variation~\cite{Mun:TCP/IP:Mobicom2002}.

Our work is inspired by numerous network and application measurement studies~\cite{Chakravorty:WWAN:Mobicom2004, Zhuang:A3:Mobicom2006, Ionut:Serendipity:IMC09}, \eg Trestian \etal characterize the relationship between users' application interests and mobility ~\cite{Ionut:Serendipity:IMC09}, Zhuang \etal investigate application-aware acceleration to improve application performance~\cite{Zhuang:A3:Mobicom2006}, and Liu \etal study the interaction between the wireless channels and applications~\cite{Liu:3GChannelAppl:Mobicom2008}. Our work complements these works with different focus and methodology. 

While many applications are built on TCP, their actual user-level performance does not match that of TCP alone due to various adaptation strategies and overheads induced by the applications. Realizing this problem, Chesterfield \etal~\cite{Chesterfield:3GMultimedia:Monet2004} evaluated the performance of streaming media application over a WWAN (Wireless Wide Area Network). But their work is limited to a customized streaming application named {\em vorbistreamer}. In a separate study, Chakravorty \etal~\cite{Chakravorty:WWAN:Mobicom2004} measured the performance of TCP and web browsing over WWANs. However, that study is also different from ours because they focus only on comparing the overall throughput across different link layers.

Unlike previous studies, \eg~\cite{Liu:3GChannelAppl:Mobicom2008, Chakravorty:WWAN:Mobicom2004, Jang:3G:MICNET2009}, which perform measurements on desktop or laptop systems, relying on cellular network data cards or phones tethered through USB as a modem, in this study, the application performance data is collected directly from end-users' devices, thus more accurately reflecting the user-perceived performance.

\nsection{Radio and Energy Optimization for Cellular Networks}
In cellular networks, there exists a radio resource control (RRC) state machine that manages the handset radio interface. It is the key coupling factor bridging the application traffic patterns and the lower-layer protocol behaviors. Previous studies~\cite{imc.3g} and~\cite{huang_mobisys12} examine the RRC state machine and its interaction with cellular traffic, for 3G UMTS and 4G LTE networks, respectively. We study for hundreds of thousands of users their state transition delay and transport-layer idle time, two key factors incurring signaling load and energy overhead, respectively, due to the LTE RRC state machine.

\textbf{DRX in 4G LTE networks.} Zhou \etal~\cite{vtc.drx} model the DRX mechanism as a semi-Markov process, with which they analytically study the effects of DRX parameters on the performance, as well as the tradeoff between the power saving and wake-up delay. Kolding \etal~\cite{iswcs.lte} also investigate the balance between throughput and power saving by changing the configuration of DRX parameters, using a web-browsing traffic model. Bontu \etal~\cite{ieee.drx} further considers the impact of DRX parameters on different applications with various delay sensitivities. Wigard \etal compares a long-DRX-only scenario and a scenario with both long and short DRX, in terms of throughput and power consumption. All above studies employing analytical models suffer from an inherent limitation: the expressiveness of an analytical model is quite limited and is unlikely to capture the characteristics of real-world traffic patterns using a statistical distribution with a few parameters. The existence of concurrent applications accessing the network further increases the difficulty of modeling the packet dynamics. In contrast, our work is the first empirical study to investigate the impact of the configurations of DRX parameters and tail timer. We overcome the above limitation by employing network traces from real smartphone users, thus more realistically revealing the complex tradeoffs incurred by various DRX parameters.

\textbf{Smartphone power modeling} has also been investigated by previous empirical measurements. The Bartendr project~\cite{mobicom.bartendr} studies the relationship between signal strength and smartphone radio power usage. PowerTutor~\cite{codes.powertutor} collects power traces for individual hardware components under controlled experiments then uses multi-variable regression to compute the coefficients for a linear power model considering all hardware components. ARO~\cite{mobisys.aro} employs an approach similar to~\cite{codes.powertutor} but focusing only on radio power usage. It performs more fine-grained simulation of transmission queues to capture state transitions. Our LTE power model is also empirically derived, but it differs from all aforementioned models in two aspects. First, it considers DRX in \RC, a new power management mechanism in LTE networks. Second, it further takes into account both uplink and downlink data rates, resulting in a more accurate estimation of the radio power consumption when the throughput is high, as is a common case in LTE networks.


\textbf{Investigation of the inactivity timers in cellular networks.} Inactivity timers, which determine the tail times, are the most important parameters in cellular radio resource management. Radio Resource Control (RRC) tail~\cite{imc.tailender}, is necessary and important for cellular networks to prevent frequent state promotions (resource allocation), which can cause unacceptably long delays for the UE, as well as additional processing overheads for the radio access network~\cite{poor, infocom_lee}. Today's cellular carriers use a static and conservative setting of the tail time in the order of many seconds, and previous studies have revealed this tail time to be the root cause of energy and radio resource inefficiencies in both 3G~\cite{imc.3g, imc.tailender, wts04, Chuah:Impacts:WCNC2002}. Recent work~\cite{falaki10_imc} investigates impact of traffic patterns on radio power management policy. The impact of inactivity timers on the UMTS network capacity~\cite{Chuah:Impacts:WCNC2002} and the UE energy consumption~\cite{Lee:Impact:WTS2004, Yeh:Energy:ITVT2009} has also been studied. Another study~\cite{imc.3g} makes a further step by characterizing the impact of operational state machine settings with real traces and conclude that the fundamental limitation of the current cellular resource management mechanism is treating all traffic according to the same RRC state machine \emph{statically and globally} configured for all users, therefore, it is difficult to balance various tradeoffs of resource utilization.

\textbf{Adaptive resource release.}
Distinct from using static timers, Liers~\etal~\cite{Liers:DynamicTimeout:PIMRC2005} propose to determine inactivity timers dynamically, based on the current load, radio resources, and processing capability. However, they only address the problem from the perspective of network capacity as to reducing the call blocking and dropping rate, and the same timer values are applied globally to all UEs at any given time. In comparison, \NAME is based on fast dormancy where resource release is requested by each individual UE. Such fine-grained control leads to much more significant savings of the radio resource and the UE energy consumption.

{\em  Fast dormancy (FD)}~\cite{fast.dormancy.1, fast.dormancy.2} is a mechanism in 3G networks for reducing the amount of tail time incurred by a device by quickly demoting it to a low energy RRC state without waiting for the tail timer to expire. TOP~\cite{qian10_icnp} proposes to leverage fast dormancy to eliminate the tail whenever possible. It {\em \bf assumes} each individual application can predict an imminent long \IBT with reasonable accuracy, and fast dormancy is only invoked when the predicted aggregate idle time across all concurrent applications is long enough. While TOP provides framework and mechanism for optimization, it does {\em not} solve the problem of prediction. In this study, we solve the open research problem of predicting \IBTS. Unlike TOP being a proposed framework with unsolved assumptions, our system \NAME is a practical working system.

MakeIdle~\cite{makeidle} uses packet timestamp information to calculate the optimal idle time before fast dormancy should be invoked that maximizes the energy saving. However, MakeIdle does not look at the application context and other useful features used in \NAME, resulting in worse performance as shown later. Moreover, MakeIdle algorithm does not consider the balance of energy saving and signaling overhead, and leaves the job of reducing the signaling overhead to another algorithm called MakeActive~\cite{makeidle}, based on shifting packets (batching). MakeActive does not work for foreground traffic, and even for background traffic, there is no guarantee that it would not affect user experience, since it may incur up to seconds extra delay. In this study, to minimize such negative impact on user experience, \NAME does not rely on any traffic shifting techniques, especially because the goal for the design of \NAME is to be working for all traffic, both foreground and background.

RadioJockey\cite{radiojockey} is another closely related study. It uses system call traces to determine the {\em end-of-session} (EOS) for each application and triggers fast dormancy if there is no active session for any of the applications. However, RadioJockey only works for background application with no user interaction, and the authors point out that the prediction accuracy would be lower for foreground traffic since user interactions may violate the correlation between system call patterns and EOS; while for \NAME, there is no such limitation and we achieve even better performance for all traffic than RadioJockey for screen-off traffic. Also, RadioJockey treats different applications separately and could not predict the {\em start-of-session} (SOS), hence when there are multiple concurrent applications, the prediction accuracy would be jeopardized, with higher instrumentation and prediction overhead. Our approach uses aggregate traffic from all applications and does not suffer from these problems. Further, RadioJockey requires complete system call traces for all applications in addition to the network traces, which incurs higher overhead than \NAME. In the evaluation section later, we compare both MakeIdle and RadioJockey with \NAME and ignore MakeActive because it alters user traffic resulting in negative impact on user experience, which is not acceptable especially for foreground traffic.


\textbf{Traffic scheduling} There exists various traffic scheduling algorithms (\eg piggyback, batching~\cite{qian12_www, mobisys10_ra}, TailEnder~\cite{imc.tailender}, and Intentional Networking~\cite{higgins10}) for optimizing resource consumption in cellular networks. For example, in piggyback~\cite{qian12_www}, transfers can be shifted earlier, or be postponed till later, so that they can potentially be overlapped with non-target transfers, thus reducing the total tail time. TailEnder~\cite{imc.tailender} schedules transfers to minimize the energy consumption while meeting user-specified deadlines by delaying transfers and transmitting them together. In addition, specialized energy saving techniques for mobile applications have been proposed for specific applications~\cite{mobisys09_wang, mobisys08_kang} and for specific protocols~\cite{mobisys07_agarwal}. The major limitations of these approaches is that they are only applicable to delay-tolerant traffic (RSS feeds, push notification \etc). \NAME can be applied to any type of traffic (in particular, delay-sensitive traffic triggered by users), and can be used together with the aforementioned scheduling techniques.

\textbf{Traffic modeling and prediction} has be explored by various previous works. A linear prediction-based time series forecasting technique is used to predict future no-data intervals for multimedia data streaming~\cite{wcnc04}. Hidden Markov Models are also used for modeling and predicting traffic of several Internet applications~\cite{Dainotti20082645}. In our work, we look at the aggregate traffic, including all different applications, and predict whether inter burst time is longer than a threshold, which is a joint effect of packets generated by all applications, and hence is more challenging and better for practical use. This specific, yet important problem for energy and network resource saving has not been studied before in mobile platforms with a large real-world data set as ours.

